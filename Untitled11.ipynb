{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQpeNXoJ9/AMDzpgRzdFdZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appababba/DQN-on-New-Atari-Domains/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7fwZSftAPAX",
        "outputId": "82fb9fa1-f76e-45d3-9cbc-3712b6e5672c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/187.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hAutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.12/dist-packages/AutoROM/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/et.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/zaxxon.bin\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q \"gymnasium[atari]\" autorom stable-baselines3\n",
        "!AutoROM --accept-license\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "try:\n",
        "    drive.flush_and_unmount()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "!rm -rf /content/drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB9hTeeVBxEy",
        "outputId": "297fa2fd-55ac-4461-9af7-6d6f45ce53b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "import os\n",
        "os.makedirs(\"videos\", exist_ok=True)\n",
        "save_dir_drive = \"/content/drive/MyDrive/PUBLIC/Models\"\n",
        "save_dir_local = \"saved_models\"\n",
        "os.makedirs(save_dir_drive, exist_ok=True)\n",
        "os.makedirs(save_dir_local, exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPh227DYBz4K",
        "outputId": "79a84aca-e2e1-4191-d455-3759e8d74df0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, os\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "_ = os.system(\"nvidia-smi\")  # should print GPU info\n",
        "import torch, torch.backends.cudnn as cudnn\n",
        "cudnn.benchmark = True\n",
        "torch.set_float32_matmul_precision(\"high\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60cl2v2jEAm_",
        "outputId": "eb133ab2-b651-4e99-aade-0dc7f727446e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ale_py\n",
        "import os, time, collections, typing as tt\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3.common import atari_wrappers\n",
        "from torch.utils.tensorboard.writer import SummaryWriter\n",
        "\n",
        "# Make folders\n",
        "os.makedirs(\"videos\", exist_ok=True)\n",
        "save_dir_drive = \"/content/drive/MyDrive/PUBLIC/Models\"\n",
        "save_dir_local = \"saved_models\"\n",
        "os.makedirs(save_dir_drive, exist_ok=True)\n",
        "os.makedirs(save_dir_local, exist_ok=True)\n",
        "\n",
        "# Mount Drive (only once at the top of the notebook)\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw9MN892ASWC",
        "outputId": "b51a7408-e33b-4de7-8997-2e9c9ef44afe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),             nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),             nn.ReLU(),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        size = self.conv(torch.zeros(1, *input_shape)).size(-1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(size, 512), nn.ReLU(),\n",
        "            nn.Linear(512, n_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.ByteTensor):\n",
        "        x = x.float() / 255.0\n",
        "        return self.fc(self.conv(x))\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        obs = self.observation_space\n",
        "        assert isinstance(obs, spaces.Box) and len(obs.shape) == 3\n",
        "        new_shape = (obs.shape[-1], obs.shape[0], obs.shape[1])\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=obs.low.min(), high=obs.high.max(), shape=new_shape, dtype=obs.dtype\n",
        "        )\n",
        "    def observation(self, observation):  # (H,W,C) -> (C,H,W)\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env, n_steps):\n",
        "        super().__init__(env)\n",
        "        obs = env.observation_space\n",
        "        assert isinstance(obs, spaces.Box)\n",
        "        self.buffer = collections.deque(maxlen=n_steps)\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=obs.low.repeat(n_steps, axis=0),\n",
        "            high=obs.high.repeat(n_steps, axis=0),\n",
        "            dtype=obs.dtype\n",
        "        )\n",
        "    def reset(self, *, seed: tt.Optional[int]=None, options: tt.Optional[dict]=None):\n",
        "        for _ in range(self.buffer.maxlen):\n",
        "            self.buffer.append(np.zeros_like(self.env.observation_space.low))\n",
        "        obs, info = self.env.reset(seed=seed, options=options)\n",
        "        return self.observation(obs), info\n",
        "    def observation(self, observation):\n",
        "        self.buffer.append(observation)\n",
        "        return np.concatenate(self.buffer, axis=0)\n",
        "\n",
        "def make_env(env_name: str, n_steps=4, render_mode=None, **kwargs):\n",
        "    print(f\"Creating environment {env_name}\")\n",
        "    env = gym.make(env_name, render_mode=render_mode, **kwargs)\n",
        "    # Use standard ALE wrappers; set noop_max>0 if you want more start-state variety\n",
        "    env = atari_wrappers.AtariWrapper(env, clip_reward=False, noop_max=0)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, n_steps=n_steps)\n",
        "    return env\n"
      ],
      "metadata": {
        "id": "pHnStAVjAV4E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Configuration\n",
        "DEFAULT_ENV_NAME = \"ALE/Qbert-v5\"\n",
        "env_name = DEFAULT_ENV_NAME\n",
        "safe_env_name = env_name.replace(\"/\", \"_\")\n",
        "\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 32\n",
        "REPLAY_SIZE = 10_000\n",
        "REPLAY_START_SIZE = 10_000      # warm-up must fit into buffer\n",
        "LEARNING_RATE = 1e-4\n",
        "SYNC_TARGET_FRAMES = 1_000\n",
        "MEAN_REWARD_BOUND = 1_000       # not used to stop anymore\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_FINAL = 0.01\n",
        "EPSILON_DECAY_LAST_FRAME = 150_000\n",
        "\n",
        "# Save throttling\n",
        "SAVE_IMPROVE_MIN  = 2.0\n",
        "SAVE_MIN_INTERVAL = 2_000\n",
        "TRAIN_MAX_FRAMES  = 120_000     # stop for class/demo\n",
        "\n",
        "# Safety: warmup can't exceed buffer\n",
        "assert REPLAY_START_SIZE <= REPLAY_SIZE, \"REPLAY_START_SIZE must be <= REPLAY_SIZE\"\n",
        "\n",
        "# Types\n",
        "State = np.ndarray\n",
        "Action = int\n",
        "BatchTensors = tt.Tuple[torch.ByteTensor, torch.LongTensor, torch.Tensor, torch.BoolTensor, torch.ByteTensor]\n",
        "\n",
        "@dataclass\n",
        "class Experience:\n",
        "    state: State\n",
        "    action: Action\n",
        "    reward: float\n",
        "    done_trunc: bool\n",
        "    new_state: State\n",
        "\n",
        "class ExperienceBuffer:\n",
        "    def __init__(self, capacity: int):\n",
        "        self.buffer = collections.deque(maxlen=capacity)\n",
        "    def __len__(self): return len(self.buffer)\n",
        "    def append(self, exp: Experience): self.buffer.append(exp)\n",
        "    def sample(self, batch_size: int) -> tt.List[Experience]:\n",
        "        idxs = np.random.choice(len(self), batch_size, replace=False)\n",
        "        return [self.buffer[i] for i in idxs]\n"
      ],
      "metadata": {
        "id": "RRYdN2rJAX5-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, env: gym.Env, exp_buffer: ExperienceBuffer):\n",
        "        self.env = env\n",
        "        self.exp_buffer = exp_buffer\n",
        "        self.state: tt.Optional[np.ndarray] = None\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self):\n",
        "        self.state, _ = self.env.reset()\n",
        "        self.total_reward = 0.0\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def play_step(self, net: DQN, device: torch.device, epsilon: float=0.0) -> tt.Optional[float]:\n",
        "        done_reward = None\n",
        "        if np.random.random() < epsilon:\n",
        "            action = self.env.action_space.sample()  # FIX: use self.env\n",
        "        else:\n",
        "            state_v = torch.as_tensor(self.state).to(device).unsqueeze(0)\n",
        "            q_vals = net(state_v)\n",
        "            action = int(torch.argmax(q_vals, dim=1).item())\n",
        "\n",
        "        new_state, reward, done, trunc, _ = self.env.step(action)\n",
        "        self.total_reward += reward\n",
        "        self.exp_buffer.append(Experience(self.state, action, float(reward), done or trunc, new_state))\n",
        "        self.state = new_state\n",
        "\n",
        "        if done or trunc:\n",
        "            done_reward = self.total_reward\n",
        "            self._reset()\n",
        "        return done_reward\n",
        "\n",
        "def batch_to_tensors(batch: tt.List[Experience], device: torch.device) -> BatchTensors:\n",
        "    states, actions, rewards, dones, new_states = [], [], [], [], []\n",
        "    for e in batch:\n",
        "        states.append(e.state); actions.append(e.action); rewards.append(e.reward)\n",
        "        dones.append(e.done_trunc); new_states.append(e.new_state)\n",
        "    states_t     = torch.as_tensor(np.asarray(states)).to(device)\n",
        "    actions_t    = torch.LongTensor(actions).to(device)\n",
        "    rewards_t    = torch.FloatTensor(rewards).to(device)\n",
        "    dones_t      = torch.BoolTensor(dones).to(device)\n",
        "    new_states_t = torch.as_tensor(np.asarray(new_states)).to(device)\n",
        "    return states_t, actions_t, rewards_t, dones_t, new_states_t\n",
        "\n",
        "def calc_loss(batch: tt.List[Experience], net: DQN, tgt_net: DQN, device: torch.device) -> torch.Tensor:\n",
        "    states_t, actions_t, rewards_t, dones_t, new_states_t = batch_to_tensors(batch, device)\n",
        "    q_sa   = net(states_t).gather(1, actions_t.unsqueeze(-1)).squeeze(-1)\n",
        "    with torch.no_grad():\n",
        "        next_q = tgt_net(new_states_t).max(1)[0]\n",
        "        next_q[dones_t] = 0.0\n",
        "    target = rewards_t + GAMMA * next_q\n",
        "    return nn.MSELoss()(q_sa, target)\n",
        "\n",
        "def record_episode(env_name, model, device, out_path, max_steps=600, fps=30):\n",
        "    env = make_env(env_name, render_mode=\"rgb_array\")\n",
        "    state, _ = env.reset()\n",
        "    frames = []\n",
        "    for step in range(max_steps):\n",
        "        with torch.no_grad():\n",
        "            q_vals = model(torch.as_tensor(state).unsqueeze(0).to(device))\n",
        "            action = int(torch.argmax(q_vals, dim=1).item())\n",
        "        state, _, done, trunc, _ = env.step(action)\n",
        "        frame = env.render()\n",
        "        if frame is not None:\n",
        "            frames.append(frame)\n",
        "        if done or trunc:\n",
        "            break\n",
        "    env.close()\n",
        "    if frames:\n",
        "        imageio.mimsave(out_path, frames, fps=fps, macro_block_size=1)\n",
        "        print(f\"Saved video: {out_path}\")\n",
        "    else:\n",
        "        print(\"No frames captured â€” check render_mode and environment setup.\")\n"
      ],
      "metadata": {
        "id": "nypVvJxNAZh8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "env = make_env(env_name)\n",
        "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "tgt_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "writer = SummaryWriter(comment=f\"-{env_name}-eps{EPSILON_DECAY_LAST_FRAME}-rs{REPLAY_START_SIZE}-sync{SYNC_TARGET_FRAMES}\")\n",
        "\n",
        "print(net)\n",
        "print(\"CFG:\", \"MEAN_REWARD_BOUND=\", MEAN_REWARD_BOUND,\n",
        "      \"REPLAY_START_SIZE=\", REPLAY_START_SIZE,\n",
        "      \"EPS_DECAY=\", EPSILON_DECAY_LAST_FRAME,\n",
        "      \"SYNC=\", SYNC_TARGET_FRAMES)\n",
        "\n",
        "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
        "agent = Agent(env, buffer)\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Early video (~20s at 30 fps)\n",
        "record_episode(env_name, net, device, \"videos/qbert_early.mp4\", max_steps=600, fps=30)\n",
        "\n",
        "frame_idx = 0\n",
        "ts_frame, ts = 0, time.time()\n",
        "start_time = time.time()\n",
        "best_m_reward = None\n",
        "last_save_frame = -10**9\n",
        "best_paths = collections.deque(maxlen=5)\n",
        "\n",
        "while True:\n",
        "    frame_idx += 1\n",
        "    if frame_idx >= TRAIN_MAX_FRAMES:\n",
        "        print(f\"Reached TRAIN_MAX_FRAMES={TRAIN_MAX_FRAMES}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
        "    reward = agent.play_step(net, device, epsilon)\n",
        "\n",
        "    # Warm-up phase: fill replay\n",
        "    if len(buffer) < REPLAY_START_SIZE:\n",
        "        if frame_idx % 1000 == 0:\n",
        "            print(f\"[Warmup] frames={frame_idx:,} buffer={len(buffer):,}/{REPLAY_START_SIZE:,} eps={epsilon:.2f}\")\n",
        "        continue\n",
        "\n",
        "    # Log on episode end\n",
        "    if reward is not None:\n",
        "        speed = (frame_idx - ts_frame) / max(1e-6, (time.time() - ts))\n",
        "        ts_frame, ts = frame_idx, time.time()\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        if 'total_rewards' not in globals():\n",
        "            total_rewards = []\n",
        "        total_rewards.append(reward)\n",
        "        m_reward = float(np.mean(total_rewards[-100:]))\n",
        "\n",
        "        if frame_idx % 1000 == 0:\n",
        "            print(f\"[Train] frames={frame_idx:,} eps={epsilon:.2f} mean100={m_reward:.2f} speed={speed:.1f} f/s elapsed={elapsed/60:.1f} min\")\n",
        "\n",
        "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
        "        writer.add_scalar(\"speed\", speed, frame_idx)\n",
        "        writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
        "        writer.add_scalar(\"reward\", reward, frame_idx)\n",
        "\n",
        "        # Throttled saving\n",
        "        if (best_m_reward is None or m_reward > best_m_reward + SAVE_IMPROVE_MIN) and \\\n",
        "           (frame_idx - last_save_frame >= SAVE_MIN_INTERVAL):\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "            model_filename = f\"{safe_env_name}-best_{int(m_reward)}-{timestamp}-eps{EPSILON_DECAY_LAST_FRAME}_rs{REPLAY_START_SIZE}_sync{SYNC_TARGET_FRAMES}.dat\"\n",
        "            p_drive = os.path.join(save_dir_drive, model_filename)\n",
        "            p_local = os.path.join(save_dir_local, model_filename)\n",
        "            torch.save(net.state_dict(), p_drive)\n",
        "            torch.save(net.state_dict(), p_local)\n",
        "            best_m_reward = m_reward\n",
        "            last_save_frame = frame_idx\n",
        "            best_paths.append(p_local)\n",
        "            print(f\"ðŸ’¾ Saved best (mean100={m_reward:.2f}) -> {model_filename}\")\n",
        "\n",
        "    # DQN update\n",
        "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
        "        tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = buffer.sample(BATCH_SIZE)\n",
        "    loss = calc_loss(batch, net, tgt_net, device)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "env.close()\n",
        "writer.close()\n",
        "\n",
        "# Reload best and record late clip\n",
        "if best_paths:\n",
        "    best_path = best_paths[-1]\n",
        "    net.load_state_dict(torch.load(best_path, map_location=device))\n",
        "    net.eval()\n",
        "    print(f\"Loaded best checkpoint: {best_path}\")\n",
        "\n",
        "record_episode(env_name, net, device, \"videos/qbert_late.mp4\", max_steps=600, fps=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "22A5S0b6Ad5F",
        "outputId": "71e44061-ff8f-4bd3-a16e-636ea8dd04e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating environment ALE/Qbert-v5\n",
            "DQN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CFG: MEAN_REWARD_BOUND= 1000 REPLAY_START_SIZE= 10000 EPS_DECAY= 150000 SYNC= 1000\n",
            "Creating environment ALE/Qbert-v5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved video: videos/qbert_early.mp4\n",
            "[Warmup] frames=1,000 buffer=1,000/10,000 eps=0.99\n",
            "[Warmup] frames=2,000 buffer=2,000/10,000 eps=0.99\n",
            "[Warmup] frames=3,000 buffer=3,000/10,000 eps=0.98\n",
            "[Warmup] frames=4,000 buffer=4,000/10,000 eps=0.97\n",
            "[Warmup] frames=5,000 buffer=5,000/10,000 eps=0.97\n",
            "[Warmup] frames=6,000 buffer=6,000/10,000 eps=0.96\n",
            "[Warmup] frames=7,000 buffer=7,000/10,000 eps=0.95\n",
            "[Warmup] frames=8,000 buffer=8,000/10,000 eps=0.95\n",
            "[Warmup] frames=9,000 buffer=9,000/10,000 eps=0.94\n",
            "ðŸ’¾ Saved best (mean100=0.00) -> ALE_Qbert-v5-best_0-20250929-0604-eps150000_rs10000_sync1000.dat\n",
            "ðŸ’¾ Saved best (mean100=25.50) -> ALE_Qbert-v5-best_25-20250929-0604-eps150000_rs10000_sync1000.dat\n",
            "[Train] frames=13,000 eps=0.91 mean100=33.75 speed=133.7 f/s elapsed=1.1 min\n",
            "ðŸ’¾ Saved best (mean100=42.50) -> ALE_Qbert-v5-best_42-20250929-0604-eps150000_rs10000_sync1000.dat\n",
            "ðŸ’¾ Saved best (mean100=44.75) -> ALE_Qbert-v5-best_44-20250929-0605-eps150000_rs10000_sync1000.dat\n",
            "ðŸ’¾ Saved best (mean100=48.50) -> ALE_Qbert-v5-best_48-20250929-0605-eps150000_rs10000_sync1000.dat\n",
            "ðŸ’¾ Saved best (mean100=51.25) -> ALE_Qbert-v5-best_51-20250929-0606-eps150000_rs10000_sync1000.dat\n",
            "ðŸ’¾ Saved best (mean100=54.00) -> ALE_Qbert-v5-best_54-20250929-0606-eps150000_rs10000_sync1000.dat\n",
            "ðŸ’¾ Saved best (mean100=77.00) -> ALE_Qbert-v5-best_77-20250929-0606-eps150000_rs10000_sync1000.dat\n",
            "ðŸ’¾ Saved best (mean100=79.75) -> ALE_Qbert-v5-best_79-20250929-0607-eps150000_rs10000_sync1000.dat\n",
            "[Train] frames=43,000 eps=0.71 mean100=67.75 speed=122.9 f/s elapsed=5.4 min\n",
            "ðŸ’¾ Saved best (mean100=82.25) -> ALE_Qbert-v5-best_82-20250929-0609-eps150000_rs10000_sync1000.dat\n",
            "ðŸ’¾ Saved best (mean100=86.00) -> ALE_Qbert-v5-best_86-20250929-0611-eps150000_rs10000_sync1000.dat\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2737049351.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPSILON_FINAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPSILON_START\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mEPSILON_DECAY_LAST_FRAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Warm-up phase: fill replay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4203035376.py\u001b[0m in \u001b[0;36mplay_step\u001b[0;34m(self, net, device, epsilon)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExperience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    558\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    559\u001b[0m         \u001b[0;34m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    558\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    559\u001b[0m         \u001b[0;34m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    325\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    326\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    558\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    559\u001b[0m         \u001b[0;34m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    325\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    326\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAtariStepReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwas_real_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# check current lives, make loss of life terminal,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mterminated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruncated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    325\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    326\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ale_py/env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_terminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_truncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"videos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK258LqSGhEH",
        "outputId": "41e66580-c782-4341-a1fb-e86e73dff2c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['qbert_early.mp4']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video\n",
        "Video(\"videos/qbert_early.mp4\", embed=True, width=480)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "btdYIfNEIAkI",
        "outputId": "9e5dff7b-5493-4ed9-8d53-5ef5e5f4e65a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls  width=\"480\" >\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}